use anyhow::Context;
// use byteorder::WriteBytesExt; // Removed unused import
use clap::{Parser, Subcommand};
use rsb::Rsb;
use rsb::types::*;
use rsb::writer::RsbWriter;
use rsg::types::UnpackedFile;
use rsg::{pack_rsg, unpack_rsg};
use std::collections::HashMap;
use std::fs;
use std::io::{Cursor, Read, Seek, SeekFrom, Write};
use std::path::{Path, PathBuf};

#[derive(Parser)]
#[command(name = "rsb-cli")]
#[command(about = "CLI for RSB/RSG resource files", long_about = None)]
struct Cli {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// RSB Operations (Unpack/Pack)
    #[command(subcommand)]
    Rsb(RsbCommands),
    /// RSG Operations (Unpack/Pack)
    #[command(subcommand)]
    Rsg(RsgCommands),
    /// BNK Operations (Unpack/Pack)
    #[command(subcommand)]
    Bnk(BnkCommands),
    /// WEM Operations (Convert/Pack)
    #[command(subcommand)]
    Wem(WemCommands),
    /// PTX Operations (Convert)
    #[command(subcommand)]
    Ptx(PtxCommands),
    /// RTON Operations (Convert)
    #[command(subcommand)]
    Rton(RtonCommands),
    /// Newton Operations (Convert)
    #[command(subcommand)]
    Newton(NewtonCommands),
    /// PAM Operations (Convert)
    #[command(subcommand)]
    Pam(PamCommands),
    /// LawnStrings Operations (Convert)
    #[command(subcommand)]
    LawnStrings(LawnStringsCommands),
    /// POPFX Operations (Convert)
    #[command(subcommand)]
    Popfx(PopfxCommands),
    /// VCDiff Patch Operations (RSBPatch)
    #[command(subcommand)]
    Patch(PatchCommands),
}

#[derive(Subcommand)]
enum PatchCommands {
    /// Create a patch from Source to Target
    Create {
        /// Source file (Dictionary/Original)
        source: PathBuf,
        /// Target file (New/Modified)
        target: PathBuf,
        /// Output Patch file
        output: PathBuf,
    },
    /// Apply a patch to Source to get Target
    Apply {
        /// Source file (Dictionary/Original)
        source: PathBuf,
        /// Patch file
        patch: PathBuf,
        /// Output Target file
        output: PathBuf,
    },
}

#[derive(Subcommand)]
enum RsbCommands {
    /// Unpack an RSB file
    Unpack {
        /// Input RSB file path
        input: PathBuf,
        /// Output directory (optional, defaults to file name stem)
        #[arg(short, long)]
        output: Option<PathBuf>,
    },
    /// Pack a directory into an RSB file
    Pack {
        /// Input directory (containing rsb_manifest.json)
        input: PathBuf,
        /// Output RSB file
        output: PathBuf,
    },
}

#[derive(Subcommand)]
enum RsgCommands {
    /// Unpack RSG packets from rsb_manifest.json (or single RSG file)
    Unpack {
        /// Input rsb_manifest.json or .rsa/rsg file
        #[arg(short, long)]
        input: PathBuf,
        /// Output directory
        #[arg(short, long)]
        output: Option<PathBuf>,
    },
    /// Pack RSG packet from folder/config
    Pack {
        /// Input directory or config
        #[arg(short, long)]
        input: PathBuf,
        /// Output RSG file
        #[arg(short, long)]
        output: PathBuf,
    },
}

#[derive(Subcommand)]
enum BnkCommands {
    /// Unpack BNK file (Binary -> JSON + WEM extraction)
    Unpack {
        /// Input file
        input: PathBuf,
        /// Output file (optional)
        #[arg(short, long)]
        output: Option<PathBuf>,
        /// Disable WEM extraction
        #[arg(long)]
        no_extract: bool,
    },
    /// Pack a BNK file from JSON and WEM files
    Pack {
        /// Input JSON file (generated by unpack-bnk)
        #[arg(short = 'j', long)]
        json: PathBuf,
        /// Directory containing WEM files
        #[arg(short = 'w', long)]
        wems: PathBuf,
        /// Output BNK file
        #[arg(short, long)]
        output: PathBuf,
    },
}

#[derive(Subcommand)]
enum WemCommands {
    /// Decode WEM to WAV/OGG/M4A
    Decode {
        /// Input WEM file
        input: PathBuf,
        /// Output file (optional)
        #[arg(short, long)]
        output: Option<PathBuf>,
        /// Path to codebooks.bin (for Vorbis)
        #[arg(short, long)]
        codebooks: Option<String>,
        /// Inline codebooks into OGG (for Vorbis)
        #[arg(long)]
        inline_codebooks: bool,
    },
    /// Encode WAV/OGG to WEM
    Encode {
        /// Input WAV/OGG file
        input: PathBuf,
        /// Output WEM file (optional)
        #[arg(short, long)]
        output: Option<PathBuf>,
        /// Force ADPCM encoding (for WAV input)
        #[arg(short, long)]
        adpcm: bool,
    },
}

#[derive(Subcommand)]
enum PtxCommands {
    /// Decode PTX to PNG (Batch from manifest)
    Decode {
        /// Input rsb_manifest.json file
        #[arg(short, long)]
        input: PathBuf,
        /// Output directory (optional, defaults to input dir)
        #[arg(short, long)]
        output: Option<PathBuf>,
        /// Treat RGBA8888 (Format 0) as PowerVR/iOS format (BGRA) instead of default (RGBA)
        #[arg(long)]
        powervr: bool,
    },
    /// Encode PNG to PTX (Batch from manifest)
    Encode {
        /// Input rsb_manifest.json file
        #[arg(short, long)]
        input: PathBuf,
        /// Output directory (optional, defaults to input dir)
        #[arg(short, long)]
        output: Option<PathBuf>,
        /// Force PowerVR/iOS format (BGRA for Format 0)
        #[arg(long)]
        powervr: bool,
    },
}

#[derive(Subcommand)]
enum RtonCommands {
    /// Decode RTON to JSON
    Decode {
        /// Input RTON file
        input: PathBuf,
        /// Output JSON file (optional)
        #[arg(short, long)]
        output: Option<PathBuf>,
        /// Encryption Seed (for encrypted RTONs)
        #[arg(long)]
        seed: Option<String>,
    },
    /// Encode JSON to RTON
    Encode {
        /// Input JSON file
        input: PathBuf,
        /// Output RTON file (optional)
        #[arg(short, long)]
        output: Option<PathBuf>,
        /// Encryption Seed (for encrypted RTONs)
        #[arg(long)]
        seed: Option<String>,
    },
}

#[derive(Subcommand)]
enum NewtonCommands {
    /// Decode Newton to XML
    Decode {
        /// Input Newton file
        input: PathBuf,
        /// Output XML file (optional)
        #[arg(short, long)]
        output: Option<PathBuf>,
    },
    /// Encode XML to Newton
    Encode {
        /// Input XML file
        input: PathBuf,
        /// Output Newton file (optional)
        #[arg(short, long)]
        output: Option<PathBuf>,
    },
}

#[derive(Subcommand)]
enum PamCommands {
    /// Decode PAM to JSON
    Decode {
        /// Input PAM file
        input: PathBuf,
        /// Output JSON file (optional)
        #[arg(short, long)]
        output: Option<PathBuf>,
    },
    /// Encode JSON/HTML to PAM
    Encode {
        /// Input JSON or HTML file
        input: PathBuf,
        /// Output PAM file (optional)
        #[arg(short, long)]
        output: Option<PathBuf>,
    },
}

#[derive(Subcommand)]
enum LawnStringsCommands {
    /// Decode LawnStrings to JSON
    Decode {
        /// Input LawnStrings file
        input: PathBuf,
        /// Output JSON file (optional)
        #[arg(short, long)]
        output: Option<PathBuf>,
    },
    /// Encode JSON to LawnStrings
    Encode {
        /// Input JSON file
        input: PathBuf,
        /// Output LawnStrings file (optional)
        #[arg(short, long)]
        output: Option<PathBuf>,
    },
}

#[derive(Subcommand)]
enum PopfxCommands {
    /// Decode Popfx to JSON
    Decode {
        /// Input Popfx file
        input: PathBuf,
        /// Output JSON file (optional)
        #[arg(short, long)]
        output: Option<PathBuf>,
    },
    /// Encode JSON to Popfx
    Encode {
        /// Input JSON file
        input: PathBuf,
        /// Output Popfx file (optional)
        #[arg(short, long)]
        output: Option<PathBuf>,
    },
}

fn main() -> anyhow::Result<()> {
    let cli = Cli::parse();

    match &cli.command {
        Commands::Rsb(cmd) => match cmd {
            RsbCommands::Unpack { input, output } => unpack_rsb(input, output)?,
            RsbCommands::Pack { input, output } => pack_rsb(input, output)?,
        },
        Commands::Rsg(cmd) => match cmd {
            RsgCommands::Unpack { input, output } => unpack_rsg_command(input, output)?,
            RsgCommands::Pack { input, output } => pack_rsg_command(input, output)?,
        },
        Commands::Bnk(cmd) => match cmd {
            BnkCommands::Unpack {
                input,
                output,
                no_extract,
            } => unpack_bnk(input, output, *no_extract)?,
            BnkCommands::Pack { json, wems, output } => pack_bnk(json, wems, output)?,
        },
        Commands::Wem(cmd) => match cmd {
            WemCommands::Decode {
                input,
                output,
                codebooks,
                inline_codebooks,
            } => wem_decode(input, output, codebooks, *inline_codebooks)?,
            WemCommands::Encode {
                input,
                output,
                adpcm,
            } => wem_encode(input, output, *adpcm)?,
        },
        Commands::Ptx(cmd) => match cmd {
            PtxCommands::Decode {
                input,
                output,
                powervr,
            } => ptx_decode(input, output, *powervr)?,
            PtxCommands::Encode {
                input,
                output,
                powervr,
            } => ptx_encode(input, output, *powervr)?,
        },
        Commands::Rton(cmd) => match cmd {
            RtonCommands::Decode {
                input,
                output,
                seed,
            } => rton_decode(input, output, seed.as_deref())?,
            RtonCommands::Encode {
                input,
                output,
                seed,
            } => rton_encode(input, output, seed.as_deref())?,
        },
        Commands::Newton(cmd) => match cmd {
            NewtonCommands::Decode { input, output } => newton_decode(input, output)?,
            NewtonCommands::Encode { input, output } => newton_encode(input, output)?,
        },
        Commands::Pam(cmd) => match cmd {
            PamCommands::Decode { input, output } => pam_decode(input, output)?,
            PamCommands::Encode { input, output } => pam_encode(input, output)?,
        },
        Commands::LawnStrings(cmd) => match cmd {
            LawnStringsCommands::Decode { input, output } => lawnstrings_decode(input, output)?,
            LawnStringsCommands::Encode { input, output } => lawnstrings_encode(input, output)?,
        },
        Commands::Popfx(cmd) => match cmd {
            PopfxCommands::Decode { input, output } => popfx_decode(input, output)?,
            PopfxCommands::Encode { input, output } => popfx_encode(input, output)?,
        },
        Commands::Patch(cmd) => handle_patch(cmd)?,
    }

    Ok(())
}

fn newton_encode(input: &Path, output: &Option<PathBuf>) -> anyhow::Result<()> {
    use std::fs;
    // Encode XML -> NTON
    let content = fs::read_to_string(input)?;
    let root: newton::MResourceGroup = serde_xml_rs::from_str(&content)?;

    let out_path = match output {
        Some(p) => p.clone(),
        None => input.with_extension("nton"),
    };

    let mut file = fs::File::create(&out_path)?;
    newton::encode_newton(&root, &mut file)?;
    println!("Encoded NTON to {:?}", out_path);
    Ok(())
}

fn newton_decode(input: &Path, output: &Option<PathBuf>) -> anyhow::Result<()> {
    use std::fs;
    // Decode NTON -> XML
    let mut file = fs::File::open(input)?;
    let root = newton::decode_newton(&mut file)?;

    let out_path = match output {
        Some(p) => p.clone(),
        None => input.with_extension("xml"),
    };

    let mut file = fs::File::create(&out_path)?;
    serde_xml_rs::to_writer(&mut file, &root)?;
    println!("Decoded NTON to {:?}", out_path);
    Ok(())
}

fn pack_bnk(json_path: &Path, wems_dir: &Path, output_path: &Path) -> anyhow::Result<()> {
    use anyhow::Context;
    use byteorder::{LittleEndian, WriteBytesExt};
    use std::fs;
    use std::io::Write; // Assuming LittleEndian for Wwise BNK

    // 1. Load JSON
    let json_file = fs::File::open(json_path).context("Failed to open JSON file")?;
    let mut bnk: bnk::Bnk = serde_json::from_reader(json_file).context("Failed to parse JSON")?;

    // 2. Scan WEM files and gather sizes
    // We need to rebuild `data_index` (DIDX) based on available WEMs.
    // The JSON might contain `embedded_media` (IDs) or `data_index`.
    // Let's rely on `embedded_media` as the source of truth for what *should* be in the BNK.

    // Check if embedded_media exists
    if bnk.embedded_media.is_empty() {
        // Fallback to data_index if embedded_media is missing (backwards compat?)
        // But data_index in JSON might have stale offsets.
        if let Some(_first) = bnk.data_index.first() {
            println!("Warning: Using data_index from JSON. Offsets will be recalculated.");
            bnk.embedded_media = bnk.data_index.iter().map(|e| e.id).collect();
        }
    }

    bnk.data_index.clear();
    let mut current_offset = 0u32;
    let mut wem_data_buffers = Vec::new();

    // Alignment for WEM data in DATA chunk. Wwise usually aligns to 16 bytes?
    // Let's assume 16 bytes alignment for now.
    // Actually, `DIDX` offsets are relative to the start of the `DATA` chunk header (or body?).
    // In `parse_bnk`: `wem_offset = data_start + entry.offset as u64;`
    // `data_start` is the position AFTER the `DATA` header (size+magic).
    // So offsets are relative to DATA content start.

    for id in &bnk.embedded_media {
        let wem_filename = format!("{}.wem", id);
        let wem_path = wems_dir.join(&wem_filename);

        // Try simple filename first, then maybe recursive search?
        // For now, strict flat directory.
        if !wem_path.exists() {
            return Err(anyhow::anyhow!("WEM file not found: {:?}", wem_path));
        }

        let mut data =
            fs::read(&wem_path).context(format!("Failed to read WEM: {:?}", wem_path))?;
        let size = data.len() as u32;

        // Alignment check/padding
        // Wwise often aligns items. Let's align to 16 bytes.
        let padding = (16 - (size % 16)) % 16;
        if padding > 0 {
            data.extend(std::iter::repeat_n(0, padding as usize));
        }

        bnk.data_index.push(bnk::DidxEntry {
            id: *id,
            offset: current_offset,
            size, // Store original size or padded size?
                  // Usually size in DIDX is the actual file size, padding is just implicit gap.
                  // But wait, if we pack them contiguously, the next offset depends on padded size.
                  // Let's trust `size` is logical size.
        });

        current_offset += data.len() as u32; // Increment by padded size
        wem_data_buffers.push(data);
    }

    // 3. Write BNK
    let mut out_file = fs::File::create(output_path).context("Failed to create output BNK")?;

    // Write Metadata chunks
    bnk.write(&mut out_file)
        .context("Failed to write BNK structure")?;

    // 4. Write DATA chunk
    if !wem_data_buffers.is_empty() {
        out_file.write_all(b"DATA")?;
        out_file.write_u32::<LittleEndian>(current_offset)?; // Total size of DATA section

        for data in wem_data_buffers {
            out_file.write_all(&data)?;
        }
    }

    println!("Repacked BNK to {:?}", output_path);
    Ok(())
}

fn unpack_rsb(input: &Path, output: &Option<PathBuf>) -> anyhow::Result<()> {
    let file = fs::File::open(input)?;
    let mut rsb = Rsb::open(file)?;

    let out_dir = match output {
        Some(p) => p.clone(),
        None => {
            // let file_stem = input.file_stem().unwrap_or_default();
            // PathBuf::from(file_stem)
            // Default to input parent folder / input filename _ unpacked?
            // Or just current dir/stem
            let file_stem = input.file_stem().unwrap_or_default();
            PathBuf::from(file_stem)
        }
    };

    if !out_dir.exists() {
        fs::create_dir_all(&out_dir)?;
    }

    println!("Unpacking {:?} to {:?}", input, out_dir);

    // Read all metadata
    let rsg_infos = rsb.read_rsg_info()?;
    let composite_infos = rsb.read_composite_info()?;
    let ptx_infos = rsb.read_ptx_info()?;
    let _autopool_infos = rsb.read_autopool_info()?;

    println!("Found {} RSG packets.", rsg_infos.len());
    println!("Found {} Composite groups.", composite_infos.len());

    let mut group_list = Vec::new();
    let mut rsg_name_list = Vec::new();
    let mut processed_pool_indices = std::collections::HashSet::new();

    // Helper to process an RSG
    // We cannot easily make this a closure due to borrow checker and Rsb/ptx_infos access.
    // So we inline or loop.

    // Iterate Composites to drive unpacking (Parity with C#)
    for composite in &composite_infos {
        let mut sub_group_list = Vec::new();

        for packet_entry in &composite.packet_info {
            // Find RSG with pool_index == packet_index
            if let Some(rsg_info) = rsg_infos
                .iter()
                .find(|r| r.pool_index == packet_entry.packet_index)
            {
                if processed_pool_indices.contains(&rsg_info.pool_index) {
                    continue;
                }
                processed_pool_indices.insert(rsg_info.pool_index);

                rsg_name_list.push(rsg_info.name.clone());

                let packet_data = rsb.extract_packet(rsg_info)?;
                // Separate RSB/RSG: Just write the packet file
                let rsg_path = out_dir.join(&rsg_info.name);

                if !rsg_path.exists() {
                    if packet_data.is_empty() {
                        println!("  Packet {} is empty, skipping write.", rsg_info.name);
                    } else {
                        fs::write(&rsg_path, &packet_data)?;
                        println!("  Extracted packet: {}", rsg_info.name);
                    }
                }

                if !packet_data.is_empty() {
                    let mut reader = std::io::Cursor::new(&packet_data);

                    match unpack_rsg(&mut reader) {
                        Ok(unpacked_files) => {
                            let res_info_list: Vec<ManifestRes> = unpacked_files
                                .iter()
                                .map(|file| {
                                    // Match PTX info
                                    let mut ptx_info = None;
                                    let mut ptx_property = None;

                                    if let Some(extra) = &file.part1_info {
                                        let global_ptx_idx =
                                            rsg_info.ptx_before_number as usize + extra.id as usize;
                                        if let Some(global_ptx) = ptx_infos.get(global_ptx_idx) {
                                            ptx_info = Some(global_ptx.clone());
                                            ptx_property = Some(ManifestPtxProperty {
                                                format: global_ptx.format,
                                                pitch: global_ptx.pitch,
                                                alpha_size: global_ptx.alpha_size,
                                                alpha_format: global_ptx.alpha_format,
                                            });
                                        }
                                    }

                                    ManifestRes {
                                        path: file.path.clone(),
                                        ptx_info,
                                        ptx_property,
                                    }
                                })
                                .collect();

                            sub_group_list.push(ManifestSubgroup {
                                name_packet: rsg_info.name.clone(),
                                category: packet_entry.category.clone(),
                                packet_info: ManifestPacketInfo {
                                    version: 3,
                                    compression_flags: 0,
                                    res: res_info_list,
                                },
                            });
                        }
                        Err(e) => {
                            eprintln!("  Error parsing RSG {}: {:?}", rsg_info.name, e);
                        }
                    }
                }
            }
        }

        group_list.push(ManifestGroup {
            name: composite.name.clone(),
            is_composite: composite.is_composite,
            subgroup: sub_group_list,
        });
    }

    // Process leftover RSGs (orphans)
    let mut default_subgroups = Vec::new();
    for rsg_info in &rsg_infos {
        if processed_pool_indices.contains(&rsg_info.pool_index) {
            continue;
        }

        rsg_name_list.push(rsg_info.name.clone());

        let packet_data = rsb.extract_packet(rsg_info)?;
        let rsg_path = out_dir.join(&rsg_info.name);

        if !rsg_path.exists() {
            if packet_data.is_empty() {
                println!("  Packet {} is empty, skipping write.", rsg_info.name);
            } else {
                fs::write(&rsg_path, &packet_data)?;
                println!("  Extracted packet: {}", rsg_info.name);
            }
        }

        if !packet_data.is_empty() {
            let mut reader = std::io::Cursor::new(&packet_data);

            match unpack_rsg(&mut reader) {
                Ok(unpacked_files) => {
                    let res_info_list: Vec<ManifestRes> = unpacked_files
                        .iter()
                        .map(|file| {
                            let mut ptx_info = None;
                            let mut ptx_property = None;

                            if let Some(extra) = &file.part1_info {
                                let global_ptx_idx =
                                    rsg_info.ptx_before_number as usize + extra.id as usize;
                                if let Some(global_ptx) = ptx_infos.get(global_ptx_idx) {
                                    ptx_info = Some(global_ptx.clone());
                                    ptx_property = Some(ManifestPtxProperty {
                                        format: global_ptx.format,
                                        pitch: global_ptx.pitch,
                                        alpha_size: global_ptx.alpha_size,
                                        alpha_format: global_ptx.alpha_format,
                                    });
                                }
                            }

                            ManifestRes {
                                path: file.path.clone(),
                                ptx_info,
                                ptx_property,
                            }
                        })
                        .collect();

                    default_subgroups.push(ManifestSubgroup {
                        name_packet: rsg_info.name.clone(),
                        category: ["Default".to_string(), "".to_string()], // Default category
                        packet_info: ManifestPacketInfo {
                            version: 3,
                            compression_flags: 0,
                            res: res_info_list,
                        },
                    });
                }
                Err(e) => {
                    eprintln!("  Error parsing RSG {}: {:?}", rsg_info.name, e);
                }
            }
        }
    }

    if !default_subgroups.is_empty() {
        group_list.push(ManifestGroup {
            name: "Default".to_string(),
            is_composite: false,
            subgroup: default_subgroups,
        });
    }

    // Write ManifestInfo (rsb_manifest.json)
    let manifest_info = RsbManifest {
        version: rsb.header.version,
        ptx_info_size: rsb.header.ptx_info_each_length,
        path: RsbPathInfo {
            rsgs: rsg_name_list,
            packet_path: "packet".to_string(),
        },
        group: group_list,
    };

    let manifest_path = out_dir.join("rsb_manifest.json");
    fs::write(
        &manifest_path,
        serde_json::to_string_pretty(&manifest_info)?,
    )?;

    println!("Unpack complete. Manifest written to {:?}", manifest_path);

    // Export description.json if version 3
    if rsb.header.version == 3 {
        let desc = rsb.read_resources_description(out_dir.to_str().unwrap_or("output"))?;
        let desc_path = out_dir.join("description.json");
        fs::write(&desc_path, serde_json::to_string_pretty(&desc)?)?;
        println!("Exported description.json to {:?}", desc_path);
    }

    Ok(())
}

fn pack_rsb(input: &Path, output: &Path) -> anyhow::Result<()> {
    // Read Global Manifest
    let rsb_manifest_path = input.join("rsb_manifest.json");
    let rsb_manifest_content = fs::read_to_string(&rsb_manifest_path)?;
    let rsb_manifest: RsbManifest = serde_json::from_str(&rsb_manifest_content)?;

    struct PackedRsg {
        name: String,
        pool_index: i32,
        ptx_number: u32,
        ptx_before_number: u32,
        data: Vec<u8>,
        packet_head_info: Vec<u8>, // To store 32 bytes head info if available
    }

    let mut packed_rsgs = Vec::new();
    let mut all_files = Vec::new(); // Global file list
    let mut ptx_infos = Vec::new(); // Global PTX list (ordered by RSG -> File)
    let mut composite_infos = Vec::new();
    let mut autopool_infos = Vec::new();

    // Pre-load PTX info map: Path -> RsbPtxInfo
    // This allows us to find PTX info for a file quickly and in correct order (iterating files in RSG).
    let mut ptx_info_map: HashMap<String, RsbPtxInfo> = HashMap::new();
    for group in &rsb_manifest.group {
        for sub in &group.subgroup {
            for res in &sub.packet_info.res {
                if let Some(ptx) = &res.ptx_info {
                    let clean_key = res.path.replace('\\', "/");
                    ptx_info_map.insert(clean_key, ptx.clone());
                }
            }
        }
    }

    // We iterate `path.rsgs` to find packets to pack (linear list).
    for (current_pool_index, packet_name) in rsb_manifest.path.rsgs.iter().enumerate() {
        println!("Packing packet: {}", packet_name);
        let rsg_dir = input.join(packet_name);
        let manifest_path = rsg_dir.join("manifest.json");
        let mut rsg_data = Vec::new();
        let mut packet_head_info = vec![0u8; 32];

        let ptx_num;
        let mut current_rsg_ptx_infos: Vec<RsbPtxInfo> = Vec::new(); // Final list after sorting

        // Map path -> ID for this packet
        let mut resource_id_map: HashMap<String, u32> = HashMap::new();

        if manifest_path.exists() {
            let manifest_content = fs::read_to_string(&manifest_path)?;
            let unpacked_files: Vec<UnpackedFile> = serde_json::from_str(&manifest_content)?;

            // Read file data from disk and collect files
            // For packing RSG, we need mutable access.
            // But we also need to build resource_id_map.

            let mut unpacked_files_for_pack = unpacked_files.clone();

            for file in &mut unpacked_files_for_pack {
                let clean_path = file.path.replace('\\', "/");
                let file_path = rsg_dir.join(&clean_path);
                file.data = fs::read(&file_path)?;

                // Add to global file list
                all_files.push(FileListInfo {
                    name_path: clean_path.clone(),
                    pool_index: current_pool_index as i32,
                });

                if let Some(part1) = &file.part1_info {
                    resource_id_map.insert(clean_path.clone(), part1.id);
                }
            }

            let mut cursor = Cursor::new(&mut rsg_data);
            pack_rsg(&mut cursor, &unpacked_files_for_pack, 4, 0)?;

            if rsg_data.len() >= 32 {
                packet_head_info.copy_from_slice(&rsg_data[..32]);
            }
        } else if input.join(packet_name).exists() {
            // Raw RSG file exists
            let rsg_path = input.join(packet_name);
            rsg_data = fs::read(&rsg_path)?;
            println!("  Using raw RSG file: {:?}", rsg_path);

            if rsg_data.len() >= 32 {
                packet_head_info.copy_from_slice(&rsg_data[..32]);
            }

            // Parse RSG to get IDs
            let mut cursor = Cursor::new(&rsg_data);
            match unpack_rsg(&mut cursor) {
                Ok(files) => {
                    for file in files {
                        if let Some(part1) = file.part1_info {
                            let clean_path = file.path.replace('\\', "/");
                            resource_id_map.insert(clean_path, part1.id);
                        }
                    }
                }
                Err(e) => {
                    println!("  Warning: Failed to parse raw RSG for IDs: {:?}", e);
                }
            }
        } else {
            println!(
                "  No manifest or raw file found for {}, packing empty.",
                packet_name
            );
        }

        // Collect PTX infos with IDs from Global Manifest
        struct PtxEntry {
            info: RsbPtxInfo,
            id: u32,
        }
        let mut collected_ptx_entries = Vec::new();

        if !rsg_data.is_empty() {
            for group in &rsb_manifest.group {
                let subgroups = &group.subgroup;

                for sub in subgroups {
                    if sub.name_packet == *packet_name {
                        // Sum up resources with ptx_info
                        for res in &sub.packet_info.res {
                            // Add to global file list for raw RSG mode
                            if !manifest_path.exists() {
                                // Only if not already added in manifest block
                                all_files.push(FileListInfo {
                                    name_path: res.path.clone(),
                                    pool_index: current_pool_index as i32,
                                });
                            }

                            if let Some(ptx_info) = &res.ptx_info {
                                let clean_key = res.path.replace('\\', "/");
                                let id = *resource_id_map.get(&clean_key).unwrap_or(&0);
                                collected_ptx_entries.push(PtxEntry {
                                    info: ptx_info.clone(),
                                    id,
                                });
                            }
                        }
                    }
                }
            }
        }

        // Sort PTX entries by ID
        collected_ptx_entries.sort_by_key(|e| e.id);

        // Fill gaps and build final list
        if let Some(max_entry) = collected_ptx_entries.last() {
            let _max_id = max_entry.id;
            let mut final_entries = Vec::new(); // indices 0..max_id
            let mut current_id = 0;

            for entry in &collected_ptx_entries {
                while current_id < entry.id {
                    // Fill gap with dummy
                    final_entries.push(RsbPtxInfo::default());
                    current_id += 1;
                }
                final_entries.push(entry.info.clone());
                current_id += 1;
            }

            ptx_num = final_entries.len() as u32;
            current_rsg_ptx_infos = final_entries;
        } else {
            ptx_num = 0;
        }

        packed_rsgs.push(PackedRsg {
            name: packet_name.clone(),
            pool_index: current_pool_index as i32,
            ptx_number: ptx_num, // Updated count
            ptx_before_number: 0,
            data: rsg_data,
            packet_head_info,
        });

        // Append collected PTX infos
        ptx_infos.extend(current_rsg_ptx_infos);
    }

    // Calculate ptx_before_number
    let mut accum_ptx = 0;
    for rsg in &mut packed_rsgs {
        rsg.ptx_before_number = accum_ptx;
        accum_ptx += rsg.ptx_number;
    }

    // Build Composite Info
    for group in &rsb_manifest.group {
        let mut packet_info_list = Vec::new();
        for sub in &group.subgroup {
            // Find packet index
            if let Some(idx) = packed_rsgs.iter().position(|r| r.name == sub.name_packet) {
                packet_info_list.push(CompositePacketInfo {
                    packet_index: idx as i32,
                    category: sub.category.clone(),
                });
            }
        }

        composite_infos.push(CompositeInfo {
            name: group.name.clone(),
            is_composite: group.is_composite,
            packet_number: packet_info_list.len() as u32,
            packet_info: packet_info_list,
        });
    }

    // AutoPool Info - mirror RSG list for now as per Sen behavior observed?
    // Or just create generic autopools.
    // Sen `WriteAutoPool`:
    // It seems to just write what was read.
    // If we don't have it, we can generate basic one or omit if optional (but file structure expects it).
    // Let's create one AutoPool per RSG for safety/parity if they mirror each other.
    for rsg in &packed_rsgs {
        autopool_infos.push(AutoPoolInfo {
            name: rsg.name.clone(),
            part0_size: 0, // values?
            part1_size: 0,
        });
    }

    // Write RSB
    let mut writer = fs::File::create(output)?;
    let mut rsb_writer = RsbWriter::new(&mut writer);

    // Header
    rsb_writer.write_header(&RsbHeader {
        version: rsb_manifest.version,
        ptx_info_each_length: rsb_manifest.ptx_info_size,
        ..Default::default()
    })?;

    let mut rsb_header_info = RsbHeader::default(); // To track offsets
    rsb_header_info.magic = *b"1bsr";
    rsb_header_info.version = rsb_manifest.version;

    // 1. File List
    let (file_list_begin, file_list_len) = rsb_writer.write_file_list(&all_files)?;
    rsb_header_info.file_list_begin_offset = file_list_begin;
    rsb_header_info.file_list_length = file_list_len;

    // 2. RSG Info List placeholder & write
    // We need RSG offsets first, so we write packets first?
    // Sen writes: Header -> Placeholders -> RSGInfo -> Composite -> AutoPool -> PTX -> Desc -> Packets.
    // But RSG Info needs offsets of Packets.
    // It seems we must reserve space or write packets later.
    // 2. File List
    if rsb_manifest.version >= 4 {
        // V4 overlap hack: FileList starts at 112, overwriting end of Header reserve (112..120)
        rsb_writer.writer.seek(SeekFrom::Start(112))?;
    }
    let (file_begin, file_len) = rsb_writer.write_file_list(&all_files)?;
    rsb_header_info.file_list_begin_offset = file_begin;
    rsb_header_info.file_list_length = file_len;

    // Sen: `WriteRSGInfo` writes placeholders or partial info, then `Pack` overwrites it or writes packets then updates RSG info?
    // `RSBFunction.Pack`:
    // Writes Header (Placeholder)
    // Writes FileList
    // Writes RSGInfo (Placeholders?)
    // Writes Composite
    // Writes AutoPool
    // Writes PTX
    // Writes Desc
    // Writes Packets
    // Updates Header & RSGInfo with real offsets.

    // Using RsbWriter:

    // Reserve RSG Info
    let rsg_info_begin = rsb_writer.writer.stream_position()? as u32;
    // Write empty bytes for RSG infos
    let rsg_count = packed_rsgs.len() as u32;
    let rsg_each_len = 204;
    rsb_writer
        .writer
        .write_all(&vec![0u8; (rsg_count * rsg_each_len) as usize])?;

    rsb_header_info.rsg_info_begin_offset = rsg_info_begin;
    rsb_header_info.rsg_info_each_length = rsg_each_len;
    rsb_header_info.rsg_number = rsg_count;

    // 3. Composite Info
    let (comp_begin, comp_each) = rsb_writer.write_composite_info(&composite_infos)?;
    rsb_header_info.composite_info_begin_offset = comp_begin;
    rsb_header_info.composite_info_each_length = comp_each;
    rsb_header_info.composite_number = composite_infos.len() as u32;

    // Part 1, 2, 3 Offsets
    // These are not written by write_composite_info, but are part of the header.
    // They are usually 0 in Sen's RSBs if not used.
    // For now, we'll set them to 0.
    rsb_header_info.part1_begin_offset = 0;
    rsb_header_info.part2_begin_offset = 0;
    rsb_header_info.part3_begin_offset = 0;

    // We used rsb_header_info for Parts.
    // We already moved packet writing after header.
    // We should update the rest of the fields for write_header call.

    rsb_header_info.packet_number = packed_rsgs.len() as u32;
    rsb_header_info.packet_info_begin_offset = rsg_info_begin; // Assuming packet info IS rsg info based on Sen behavior
    rsb_header_info.packet_info_each_length = rsg_each_len;

    // 4. AutoPool Info
    let (auto_begin, auto_each) = rsb_writer.write_autopool_info(&autopool_infos)?;
    rsb_header_info.autopool_info_begin_offset = auto_begin;
    rsb_header_info.autopool_info_each_length = auto_each;
    rsb_header_info.autopool_number = autopool_infos.len() as u32;

    // 5. PTX Info
    let ptx_begin = rsb_writer.write_ptx_info(&ptx_infos, rsb_manifest.ptx_info_size)?;
    rsb_header_info.ptx_info_begin_offset = ptx_begin;
    rsb_header_info.ptx_info_each_length = rsb_manifest.ptx_info_size;
    rsb_header_info.ptx_number = ptx_infos.len() as u32;

    // 6. Description
    let desc_path = input.join("description.json");
    if desc_path.exists() {
        println!("  Found description.json, writing ResourcesDescription...");
        let desc_content = fs::read_to_string(&desc_path)?;
        let desc: ResourcesDescription = serde_json::from_str(&desc_content)?;
        rsb_writer.write_resources_description(&desc, &mut rsb_header_info)?;
    }

    // Align
    fn align<W: Write + Seek>(w: &mut W) -> anyhow::Result<()> {
        let pos = w.stream_position()?;
        if pos % 4096 != 0 {
            let pad = 4096 - (pos % 4096);
            w.write_all(&vec![0u8; pad as usize])?;
        }
        Ok(())
    }
    align(&mut rsb_writer.writer)?;

    // 7. Packets
    let mut updated_rsg_infos = Vec::new();
    let mut ptx_counts = Vec::new();

    for rsg in &packed_rsgs {
        let offset = rsb_writer.writer.stream_position()? as u32;
        rsb_writer.writer.write_all(&rsg.data)?;
        let length = rsg.data.len() as u32;
        align(&mut rsb_writer.writer)?;

        updated_rsg_infos.push(RsgInfo {
            name: rsg.name.clone(),
            rsg_offset: offset,
            rsg_length: length,
            pool_index: rsg.pool_index,
            packet_head_info: Some(rsg.packet_head_info.clone()),
            ptx_number: rsg.ptx_number, // Not used in struct but logic?
            ptx_before_number: rsg.ptx_before_number,
        });
        ptx_counts.push((rsg.ptx_number, rsg.ptx_before_number));
    }
    let file_end = rsb_writer.writer.stream_position()? as u32;
    rsb_header_info.file_offset = file_end;

    // Rewind and write RSG Info
    rsb_writer
        .writer
        .seek(SeekFrom::Start(rsg_info_begin as u64))?;
    rsb_writer.write_rsg_info(&updated_rsg_infos, &ptx_counts)?;

    // Final Header Update
    rsb_writer.writer.seek(SeekFrom::Start(0))?;

    if rsb_manifest.version >= 4 {
        // Recover the overlapping FileList bytes (112..120)
        // Since rsb_writer.writer is BufWriter (Write-only wrapper), we flush and read from file path
        rsb_writer.writer.flush()?;

        let mut f = fs::File::open(output)?;
        f.seek(SeekFrom::Start(112))?;
        let mut buf = [0u8; 8];
        f.read_exact(&mut buf)?;

        // Inject into packet_info fields to preserve them during write_header
        rsb_header_info.packet_info_begin_offset =
            u32::from_le_bytes(buf[0..4].try_into().unwrap());
        rsb_header_info.packet_info_each_length = u32::from_le_bytes(buf[4..8].try_into().unwrap());

        rsb_writer.writer.seek(SeekFrom::Start(0))?;
    }

    rsb_writer.write_header(&rsb_header_info)?; // Write full header with all offsets

    println!("Pack complete. Written to {:?}", output);

    Ok(())
}

fn pam_encode(input: &Path, output: &Option<PathBuf>) -> anyhow::Result<()> {
    use std::fs;

    // Encode JSON/HTML -> PAM
    let extension = input
        .extension()
        .unwrap_or_default()
        .to_string_lossy()
        .to_lowercase();

    let pam_value = if extension == "html" {
        // Parse HTML to extract JSON
        let content = fs::read_to_string(input)?;
        pam::html5::parse_html_pam(&content)?
    } else {
        // Parse JSON directly
        let content = fs::read_to_string(input)?;
        serde_json::from_str(&content)?
    };

    let out_path = match output {
        Some(p) => p.clone(),
        None => input.with_extension("pam"),
    };

    let mut file = fs::File::create(&out_path)?;
    pam::encode_pam(&pam_value, &mut file)?;
    println!("Encoded PAM to {:?}", out_path);
    Ok(())
}

fn pam_decode(input: &Path, output: &Option<PathBuf>) -> anyhow::Result<()> {
    use std::fs;

    // Decode PAM -> JSON
    let mut file = fs::File::open(input)?;
    let pam_value = pam::decode_pam(&mut file)?;

    let out_path = match output {
        Some(p) => p.clone(),
        None => input.with_extension("json"),
    };

    fs::write(&out_path, serde_json::to_string_pretty(&pam_value)?)?;
    println!("Decoded PAM to {:?}", out_path);
    Ok(())
}

fn lawnstrings_encode(input: &Path, output: &Option<PathBuf>) -> anyhow::Result<()> {
    use std::fs;
    // Encode JSON -> LawnStrings
    let content = fs::read_to_string(input)?;
    let strings: lawnstrings::LawnStringsRoot = serde_json::from_str(&content)?;

    let out_path = match output {
        Some(p) => p.clone(),
        None => input.with_extension("txt"), // LawnStrings are .txt usually, sometimes .st
    };

    let text_content = lawnstrings::write_lawn_strings(&strings)?;
    fs::write(&out_path, text_content)?;
    println!("Encoded LawnStrings to {:?}", out_path);
    Ok(())
}

fn lawnstrings_decode(input: &Path, output: &Option<PathBuf>) -> anyhow::Result<()> {
    use std::fs;
    // Decode LawnStrings -> JSON
    let content = fs::read_to_string(input)?;
    let strings = lawnstrings::parse_lawn_strings(&content)?;

    let out_path = match output {
        Some(p) => p.clone(),
        None => input.with_extension("json"),
    };

    fs::write(&out_path, serde_json::to_string_pretty(&strings)?)?;
    println!("Decoded LawnStrings to {:?}", out_path);
    Ok(())
}

fn popfx_encode(input: &Path, output: &Option<PathBuf>) -> anyhow::Result<()> {
    use std::fs;
    // Encode JSON -> Popfx
    let content = fs::read_to_string(input)?;
    let popfx: popfx::PopcapRenderEffectObject = serde_json::from_str(&content)?;

    let out_path = match output {
        Some(p) => p.clone(),
        None => input.with_extension("pop"),
    };

    let mut file = fs::File::create(&out_path)?;
    popfx::encode_popfx(&popfx, &mut file)?;
    println!("Encoded Popfx to {:?}", out_path);
    Ok(())
}

fn popfx_decode(input: &Path, output: &Option<PathBuf>) -> anyhow::Result<()> {
    use std::fs;
    // Decode Popfx -> JSON
    let mut file = fs::File::open(input)?;
    let popfx = popfx::decode_popfx(&mut file)?;

    let out_path = match output {
        Some(p) => p.clone(),
        None => input.with_extension("json"),
    };

    fs::write(&out_path, serde_json::to_string_pretty(&popfx)?)?;
    println!("Decoded Popfx to {:?}", out_path);
    Ok(())
}

fn wem_encode(input: &Path, output: &Option<PathBuf>, adpcm: bool) -> anyhow::Result<()> {
    use anyhow::Context;
    let extension = input
        .extension()
        .and_then(|e| e.to_str())
        .unwrap_or("")
        .to_lowercase();

    let output = match output {
        Some(p) => p.clone(),
        None => input.with_extension("wem"),
    };

    if extension == "m4a" || extension == "aac" {
        // M4A/AAC Path
        println!("Encoding M4A/AAC: {:?}", input);

        // 1. Probe Metadata
        let (channels, sample_rate, avg_bytes) = wem::probe_m4a_metadata(input)?;

        println!("  Detected: {} Hz, {} Channels", sample_rate, channels);

        // 2. Pack
        let file = fs::File::open(input)?;
        let mut packer = wem::M4aToWem::new(file)?;
        packer.set_metadata(channels, sample_rate, avg_bytes);

        let mut out_file = fs::File::create(&output)?;
        packer.process(&mut out_file)?;
    } else if extension == "wav" {
        // WAV Path (PCM or ADPCM)
        println!("Encoding WAV: {:?}", input);
        let file = fs::File::open(input).context("Failed to open input WAV")?;
        let mut out_file = fs::File::create(&output).context("Failed to create output WEM")?;

        if adpcm {
            println!("  Encoding to ADPCM...");
            let mut packer = wem::adpcm::WavToAdpcm::new(file)?;
            packer.process(&mut out_file)?;
        } else {
            println!("  Encoding to PCM...");
            let mut packer = wem::WavToWem::new(file)?;
            packer.process(&mut out_file)?;
        }
    } else if extension == "ogg" || extension == "logg" {
        // OGG Path (Default)
        println!("Encoding OGG: {:?}", input);
        let file = fs::File::open(input).context("Failed to open input OGG")?;
        let mut packer = wem::OggToWem::new(file);
        let mut out_file = fs::File::create(&output).context("Failed to create output WEM")?;
        packer
            .process(&mut out_file)
            .context("Failed to pack WEM")?;
    } else {
        anyhow::bail!("Unsupported file extension: .{}", extension);
    }

    println!("Encoded WEM to {:?}", output);
    Ok(())
}

fn unpack_bnk(input: &Path, output: &Option<PathBuf>, no_extract: bool) -> anyhow::Result<()> {
    let mut file = fs::File::open(input)?;
    let bnk = bnk::Bnk::new(&mut file).context("Failed to parse BNK")?;

    let out_dir = match output {
        Some(p) => p.parent().unwrap_or(Path::new(".")).to_path_buf(),
        None => input.parent().unwrap_or(Path::new(".")).to_path_buf(),
    };

    let json_path = match output {
        Some(p) => p.clone(),
        None => input.with_extension("json"),
    };

    // Serialize to JSON
    fs::write(&json_path, serde_json::to_string_pretty(&bnk)?)?;
    println!("Decoded BNK to {:?}", json_path);

    // Extract WEMs
    if !no_extract && let Some(data_start) = bnk.data_chunk_offset {
        let extract_dir = out_dir.join(input.file_stem().unwrap_or_default());
        if !extract_dir.exists() {
            fs::create_dir_all(&extract_dir)?;
        }

        // Sort index by offset to optimize seeking logic?
        // Actually just seek is fine for SSDs, but let's be safe.
        // The entries usually come in order anyway?

        let mut count = 0;
        for entry in &bnk.data_index {
            let wem_offset = data_start + entry.offset as u64;
            let wem_size = entry.size as usize;

            // Seek and read
            file.seek(SeekFrom::Start(wem_offset))?;
            let mut wem_data = vec![0u8; wem_size];
            file.read_exact(&mut wem_data)?;

            let wem_name = format!("{}.wem", entry.id);
            let wem_path = extract_dir.join(wem_name);
            fs::write(&wem_path, &wem_data)?;
            count += 1;
        }

        if count > 0 {
            println!(
                "Extracted {} embedded WEM files to {:?}",
                count, extract_dir
            );
        }
    }

    Ok(())
}

fn wem_decode(
    input: &Path,
    output: &Option<PathBuf>,
    codebooks: &Option<String>,
    inline_codebooks: bool,
) -> anyhow::Result<()> {
    let mut file = fs::File::open(input)?;

    // Auto-detect format
    let format_tag = wem::wav::get_wem_format(&mut file).unwrap_or(0);
    file.seek(std::io::SeekFrom::Start(0))?;

    let default_extension = match format_tag {
        0xFFFF => "ogg",          // Vorbis
        0xAAC0 => "m4a",          // AAC
        0x0001 | 0xFFFE => "wav", // PCM
        _ => "wav",               // Default fallback
    };

    let out_path = match output {
        Some(p) => p.clone(),
        None => input.with_extension(default_extension),
    };

    println!(
        "Decoding {:?} -> {:?} (Format: {:#06X})",
        input, out_path, format_tag
    );

    // Codebook handling (always needed for Vorbis, even repack)
    let codebooks_lib = if let Some(path_str) = codebooks {
        wem::CodebookLibrary::from_file(path_str).context("Failed to load external codebooks")?
    } else {
        wem::CodebookLibrary::embedded_aotuv()
    };

    let mut out_file = fs::File::create(&out_path)?;

    match format_tag {
        0xFFFF => {
            // Vorbis -> OGG (Repack)
            println!("  Format: Vorbis (repacking to OGG)");
            // Use builder pattern to respect inline_codebooks
            let mut converter =
                wem::WwiseRiffVorbis::builder(std::io::BufReader::new(file), codebooks_lib)
                    .inline_codebooks(inline_codebooks)
                    .full_setup(inline_codebooks)
                    .build()
                    .map_err(|e| anyhow::anyhow!("Vorbis init failed: {:?}", e))?;

            converter
                .generate_ogg(&mut out_file)
                .map_err(|e| anyhow::anyhow!("OGG generation failed: {:?}", e))?;
        }
        0xAAC0 => {
            // AAC -> M4A (Extract)
            println!("  Format: AAC (extracting to M4A)");
            // Read entire file to buffer for extraction
            let mut buffer = Vec::new();
            file.read_to_end(&mut buffer)?;
            let cursor = std::io::Cursor::new(buffer);
            wem::aac::extract_wem_aac(cursor, &mut out_file).context("Failed to extract AAC")?;
        }
        _ => {
            // PCM/ADPCM -> WAV (Decode)
            println!("  Format: PCM/ADPCM (decoding to WAV)");
            let reader = std::io::BufReader::new(file);
            // pass codebooks by reference
            wem::wav::wem_to_wav(reader, &mut out_file, &codebooks_lib)
                .map_err(|e| anyhow::anyhow!("WAV decoding failed: {:?}", e))?;
        }
    }

    println!("Decoding successful: {:?}", out_path);
    Ok(())
}

fn handle_patch(cmd: &PatchCommands) -> anyhow::Result<()> {
    match cmd {
        PatchCommands::Create {
            source,
            target,
            output,
        } => {
            let mut src_file = fs::File::open(source).context("Failed to open Source file")?;
            let mut tgt_file = fs::File::open(target).context("Failed to open Target file")?;
            let mut out_file = fs::File::create(output).context("Failed to create Output file")?;

            println!(
                "Creating patch (Interleaved): {:?} -> {:?} = {:?}",
                source, target, output
            );
            patch::encode(&mut src_file, &mut tgt_file, &mut out_file)
                .map_err(|e| anyhow::anyhow!("Patch creation failed: {:?}", e))?;
            println!("Patch created successfully.");
        }
        PatchCommands::Apply {
            source,
            patch,
            output,
        } => {
            let mut src_file = fs::File::open(source).context("Failed to open Source file")?;
            let mut patch_file = fs::File::open(patch).context("Failed to open Patch file")?;
            let mut out_file = fs::File::create(output).context("Failed to create Output file")?;
            println!("Applying patch: {:?} + {:?} = {:?}", source, patch, output);
            patch::decode(&mut src_file, &mut patch_file, &mut out_file)
                .map_err(|e| anyhow::anyhow!("Patch application failed: {:?}", e))?;
            println!("Patch applied successfully.");
        }
    }
    Ok(())
}

fn rton_encode(input: &Path, output: &Option<PathBuf>, seed: Option<&str>) -> anyhow::Result<()> {
    // Encode JSON -> RTON
    let content = fs::read_to_string(input)?;
    let rton_value: rton::RtonValue = serde_json::from_str(&content)?;

    let out_path = match output {
        Some(p) => p.clone(),
        None => input.with_extension("rton"),
    };

    let mut file = fs::File::create(&out_path)?;
    rton::to_writer(&mut file, &rton_value, seed)?;
    println!("Encoded RTON to {:?}", out_path);
    Ok(())
}

fn rton_decode(input: &Path, output: &Option<PathBuf>, seed: Option<&str>) -> anyhow::Result<()> {
    // Decode RTON -> JSON (Default for .rton or others)
    let mut file = fs::File::open(input)?;
    let rton_value: rton::RtonValue = rton::from_reader(&mut file, seed)?;

    let out_path = match output {
        Some(p) => p.clone(),
        None => input.with_extension("json"),
    };

    fs::write(&out_path, serde_json::to_string_pretty(&rton_value)?)?;
    println!("Decoded RTON to {:?}", out_path);
    Ok(())
}

fn ptx_decode(input: &Path, output: &Option<PathBuf>, is_powervr: bool) -> anyhow::Result<()> {
    // Input should be rsb_manifest.json
    let input_dir = input.parent().unwrap_or(Path::new("."));
    let out_dir = match output {
        Some(p) => p.clone(),
        None => input_dir.to_path_buf(),
    };

    println!("Reading manifest from {:?}", input);
    let content = fs::read_to_string(input)?;
    // Try to parse as RsbManifest
    let manifest: rsb::types::RsbManifest = serde_json::from_str(&content)
        .map_err(|e| anyhow::anyhow!("Failed to parse rsb_manifest.json: {}", e))?;

    // Collect all resources with ptx_info
    let mut tasks = Vec::new();

    for group in manifest.group {
        for subgroup in group.subgroup {
            for res in subgroup.packet_info.res {
                if let Some(ptx_info) = res.ptx_info {
                    tasks.push((subgroup.name_packet.clone(), res.path.clone(), ptx_info));
                }
            }
        }
    }

    println!("Found {} PTX textures to decode.", tasks.len());

    // Process in parallel
    use rayon::prelude::*;
    tasks.par_iter().for_each(|(subgroup_name, path, info)| {
        // Extracted files are in: {InputRoot}/{SubgroupName}/{Path}
        // Path in JSON uses backslashes, e.g. "IMAGES\\480\\..."

        let relative_path = path.replace("\\", "/");
        // Construct full input path
        let full_input_path = input_dir.join(subgroup_name).join(&relative_path);

        // Output PNG next to the PTX
        let full_output_path = out_dir
            .join(subgroup_name)
            .join(&relative_path)
            .with_extension("png");

        if !full_input_path.exists() {
            // println!("Skipping missing file: {:?}", full_input_path);
            return;
        }

        // Create parent dir
        if let Some(parent) = full_output_path.parent() {
            let _ = fs::create_dir_all(parent);
        }

        let width = info.width as u32;
        let height = info.height as u32;
        let format_code = info.format;

        if let Ok(data) = fs::read(&full_input_path) {
            match ptx::PtxDecoder::decode(&data, width, height, format_code, None, is_powervr) {
                Ok(img) => {
                    if let Err(e) = img.save(&full_output_path) {
                        println!("Failed to save {:?}: {:?}", full_output_path, e);
                    }
                }
                Err(e) => {
                    println!("Failed to decode {:?}: {:?}", full_input_path, e);
                }
            }
        }
    });

    println!("PTX decoding complete.");
    Ok(())
}

fn ptx_encode(input: &Path, output: &Option<PathBuf>, is_powervr: bool) -> anyhow::Result<()> {
    // Input should be rsb_manifest.json
    let input_dir = input.parent().unwrap_or(Path::new("."));
    let out_dir = match output {
        Some(p) => p.clone(),
        None => input_dir.to_path_buf(),
    };

    println!("Reading manifest from {:?}", input);
    let content = fs::read_to_string(input)?;
    let manifest: rsb::types::RsbManifest = serde_json::from_str(&content)
        .map_err(|e| anyhow::anyhow!("Failed to parse rsb_manifest.json: {}", e))?;

    // Collect all resources with ptx_info
    let mut tasks = Vec::new();

    for group in manifest.group {
        for subgroup in group.subgroup {
            for res in subgroup.packet_info.res {
                if let Some(ptx_info) = res.ptx_info {
                    tasks.push((subgroup.name_packet.clone(), res.path.clone(), ptx_info));
                }
            }
        }
    }

    println!("Found {} textures to encode.", tasks.len());

    use rayon::prelude::*;
    tasks.par_iter().for_each(|(subgroup_name, path, info)| {
        let relative_path = path.replace("\\", "/");
        // Look for PNG first
        let png_path = input_dir
            .join(subgroup_name)
            .join(&relative_path)
            .with_extension("png");

        // Target PTX path
        let ptx_path = out_dir.join(subgroup_name).join(&relative_path);

        if !png_path.exists() {
            // println!("Skipping missing PNG: {:?}", png_path);
            return;
        }

        // Create parent dir
        if let Some(parent) = ptx_path.parent() {
            let _ = fs::create_dir_all(parent);
        }

        if let Ok(img) = image::open(&png_path) {
            let format = ptx::PtxFormat::from(info.format);

            // Handle PowerVR/iOS BGRA swap for Format 0 (RGBA8888)
            let mut img_to_encode = img;
            if is_powervr && format == ptx::PtxFormat::Rgba8888 {
                // Swap R and B channels
                let mut rgba = img_to_encode.to_rgba8();
                for pixel in rgba.pixels_mut() {
                    let r = pixel[0];
                    let b = pixel[2];
                    pixel[0] = b;
                    pixel[2] = r;
                }
                img_to_encode = image::DynamicImage::ImageRgba8(rgba);
            }

            match ptx::PtxEncoder::encode(&img_to_encode, format) {
                Ok(data) => {
                    if let Err(e) = fs::write(&ptx_path, data) {
                        println!("Failed to write {:?}: {:?}", ptx_path, e);
                    }
                }
                Err(e) => {
                    println!("Failed to encode {:?}: {:?}", png_path, e);
                }
            }
        } else {
            println!("Failed to open image: {:?}", png_path);
        }
    });

    println!("PTX encoding complete.");
    Ok(())
}

fn unpack_rsg_command(input: &Path, output: &Option<PathBuf>) -> anyhow::Result<()> {
    // Input is rsb_manifest.json
    let input_dir = input.parent().unwrap_or(Path::new("."));
    let out_dir = match output {
        Some(p) => p.clone(),
        None => input_dir.to_path_buf(),
    };

    println!("Reading manifest from {:?}", input);
    let content = fs::read_to_string(input)?;
    let manifest: RsbManifest = serde_json::from_str(&content)?;

    println!(
        "Processing {} RSG packets from manifest...",
        manifest.path.rsgs.len()
    );

    use rayon::prelude::*;
    manifest.group.par_iter().for_each(|group| {
        for subgroup in &group.subgroup {
            let packet_name = &subgroup.name_packet;
            let packet_path = input_dir.join(packet_name);

            if !packet_path.exists() {
                continue;
            }

            // Output folder for this packet
            let packet_out_dir = out_dir.join(packet_name);
            if fs::create_dir_all(&packet_out_dir).is_err() {
                continue;
            }

            // Read packet data
            if let Ok(data) = fs::read(&packet_path) {
                let mut reader = std::io::Cursor::new(&data);
                if let Ok(unpacked_files) = unpack_rsg(&mut reader) {
                    // Write manifest.json for packing
                    let manifest_path = packet_out_dir.join("manifest.json");
                    if let Ok(json) = serde_json::to_string_pretty(&unpacked_files) {
                        let _ = fs::write(&manifest_path, json);
                    }

                    for file in unpacked_files {
                        let clean_path = file.path.replace('\\', "/");
                        let target_path = packet_out_dir.join(&clean_path);

                        if let Some(parent) = target_path.parent() {
                            let _ = fs::create_dir_all(parent);
                        }
                        let _ = fs::write(&target_path, &file.data);
                    }
                }
            }
        }
    });

    println!("RSG unpack complete.");
    Ok(())
}

fn pack_rsg_command(input: &Path, output: &Path) -> anyhow::Result<()> {
    // Expect manifest.json inside input folder
    let manifest_path = input.join("manifest.json");
    if !manifest_path.exists() {
        return Err(anyhow::anyhow!(
            "manifest.json not found in input directory"
        ));
    }

    let manifest_content = fs::read_to_string(&manifest_path)?;
    let mut unpacked_files: Vec<UnpackedFile> = serde_json::from_str(&manifest_content)?;

    for file in &mut unpacked_files {
        let clean_path = file.path.replace('\\', "/");
        let file_path = input.join(clean_path);
        file.data = fs::read(&file_path)?;
    }

    let mut out_file = fs::File::create(output)?;
    pack_rsg(&mut out_file, &unpacked_files, 4, 0)?;

    println!("Packed RSG to {:?}", output);
    Ok(())
}
